{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c35e4513",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Importing-Raw-Data\" data-toc-modified-id=\"Importing-Raw-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Importing Raw Data</a></span></li><li><span><a href=\"#Importing-enriched-data\" data-toc-modified-id=\"Importing-enriched-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Importing enriched data</a></span></li><li><span><a href=\"#Spatial-Join\" data-toc-modified-id=\"Spatial-Join-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Spatial Join</a></span></li><li><span><a href=\"#Aggregation\" data-toc-modified-id=\"Aggregation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Aggregation</a></span></li><li><span><a href=\"#Plots\" data-toc-modified-id=\"Plots-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Plots</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "94b0cf7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T14:36:55.567307Z",
     "start_time": "2024-02-06T14:36:55.564551Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import datetime\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd357455",
   "metadata": {},
   "source": [
    "# Importing Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7387df3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T14:04:32.586935Z",
     "start_time": "2024-02-06T14:04:32.581140Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_osm_data(country):\n",
    "    import geopandas as gpd\n",
    "    import datetime\n",
    "    from os import listdir\n",
    "    from os.path import isfile, join\n",
    "    gdfs_osm=[]\n",
    "\n",
    "    zipped_shapefile_path = '/mnt/CAS/20240101_foss4g/datasets/in/countries/%s/' %(country)\n",
    "    onlyfiles = [f for f in listdir(zipped_shapefile_path) if isfile(join(zipped_shapefile_path, f)) if '-latest-' in f]\n",
    "    print(onlyfiles)\n",
    "    osm_buildings_stat=[]\n",
    "    for file in onlyfiles:    \n",
    "        print(datetime.datetime.now(),'importing osm data for',country,'-',file)\n",
    "        gdf_osm = gpd.read_file('zip://' + zipped_shapefile_path+file)\n",
    "        gdf_osm.columns=['osm-id','osm-code','osm-fclass','osm-name','osm-type','geometry']\n",
    "        print(datetime.datetime.now(),'imported',len(gdf_osm),'rows')\n",
    "        print(datetime.datetime.now(),gdf_osm['osm-fclass'].unique())\n",
    "        gdf_osm['source']='osm'\n",
    "        gdf_osm['dataset']='geofabrik'\n",
    "        gdf_osm['country']=country\n",
    "        gdfs_osm.append(gdf_osm)\n",
    "    import pandas as pd\n",
    "    gdfs_osm=pd.concat(gdfs_osm)\n",
    "    return gdfs_osm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa0a83d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T14:29:53.359667Z",
     "start_time": "2024-02-01T14:29:53.354810Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_eubucco_data(country):\n",
    "    import warnings\n",
    "    import datetime\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    import geopandas as gpd\n",
    "    import pandas as pd\n",
    "\n",
    "    zipped_gpkg_path = '/mnt/CAS/20240101_foss4g/datasets/in/countries/%s/eubucco.gpkg.zip' %(country)\n",
    "    eubucco_buildings_stat=[]\n",
    "    print(datetime.datetime.now(),'importing Eubucco data for',country)\n",
    "    gdf_eubucco = gpd.read_file(zipped_gpkg_path)\n",
    "    print(datetime.datetime.now(),'imported',len(gdf_eubucco),'rows')\n",
    "    gdf_eubucco['source']='eubucco'\n",
    "    gdf_eubucco['dataset']='eubucco'\n",
    "    gdf_eubucco['country']=country\n",
    "    gdf_eubucco['eubucco-id']=gdf_eubucco['id']\n",
    "    gdf_eubucco=gdf_eubucco.to_crs(4326)\n",
    "    return gdf_eubucco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c16ff8ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T14:29:53.365369Z",
     "start_time": "2024-02-01T14:29:53.361232Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_dbsm_data(country,country_extended):\n",
    "    #https://jeodpp.jrc.ec.europa.eu/ftp/jrc-opendata/DBSM/DBSM_Europe_R2023/per-country/\n",
    "    import warnings\n",
    "    import datetime\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    import geopandas as gpd\n",
    "    jrc_bdsm = '/mnt/CAS/20240101_foss4g/datasets/in/DBSM_Europe_R2023_v1.zip!DBSM_Europe_R2023_v1/dbsm-v1-%s-merge.gpkg' %(country_extended)\n",
    "    print(datetime.datetime.now(),'importing JRC-dbsm data for',country,':',country_extended)\n",
    "    gdf_jrc = gpd.read_file('zip://' + jrc_bdsm)\n",
    "    gdf_jrc['dataset']='jrc'\n",
    "    gdf_jrc['country']=country\n",
    "    gdf_jrc['jrc-id']=gdf_jrc.index\n",
    "    print(datetime.datetime.now(),'imported',len(gdf_jrc),'rows')\n",
    "    gdf_jrc=gdf_jrc.to_crs(4326)\n",
    "    return gdf_jrc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "051ad4f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-01T14:29:53.370675Z",
     "start_time": "2024-02-01T14:29:53.366934Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_microsoft_data(country):\n",
    "    import warnings\n",
    "    import datetime\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    import geopandas as gpd\n",
    "    import pandas as pd\n",
    "\n",
    "    zipped_gpkg_path = '/mnt/CAS/20240101_foss4g/datasets/in/countries/%s/microsoft.gpkg' %(country)\n",
    "    print(datetime.datetime.now(),'importing Microsoft data for',country)\n",
    "    gdf_microsoft = gpd.read_file(zipped_gpkg_path)\n",
    "    print(datetime.datetime.now(),len(gdf_microsoft))\n",
    "    gdf_microsoft['source']='microsoft'\n",
    "    gdf_microsoft['dataset']='microsoft'\n",
    "    gdf_microsoft['country']=country\n",
    "    gdf_microsoft['microsoft-id']=gdf_microsoft.index\n",
    "    return gdf_microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7fd3690b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T10:46:11.344144Z",
     "start_time": "2024-02-07T10:46:10.880796Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_nuts(country):\n",
    "    import geopandas as gpd\n",
    "    zipped_shapefile_path = '/mnt/CAS/20240101_foss4g/datasets/in/NUTS_RG_01M_2016_4326.shp.zip'\n",
    "    gdf_lau = gpd.read_file('zip://' + zipped_shapefile_path)\n",
    "    geo_lau=gdf_lau[(gdf_lau['CNTR_CODE']==country) &(gdf_lau['LEVL_CODE']==3)]\n",
    "    geo_lau=geo_lau.reset_index()\n",
    "    del(geo_lau['index'])\n",
    "    return geo_lau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ba3c91",
   "metadata": {},
   "source": [
    "# Importing enriched data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bf69e1e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-08T07:42:54.425889Z",
     "start_time": "2024-02-08T07:42:54.334227Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_enriched_data(country,dataset):\n",
    "    import geopandas as gpd\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    print(datetime.datetime.now(),'importing',country,dataset)\n",
    "    geobuildings=gpd.read_file('/mnt/CAS/20240101_foss4g/datasets/in/countries/%s/%s_enriched.gpkg'%(country,dataset))\n",
    "    if dataset=='microsoft':\n",
    "        if not('microsoft-id' in list(geobuildings.columns)):\n",
    "            geobuildings['microsoft-id']=geobuildings.index\n",
    "    \n",
    "    for col in ['area_sqm','num_vertices']:\n",
    "        column_dtype = geobuildings[col].dtype\n",
    "        if column_dtype == 'object':\n",
    "            print(datetime.datetime.now(),\"The column %s contains strings. We convert to float\" %(col))\n",
    "            geobuildings[col] = pd.to_numeric(geobuildings[col], errors='coerce')\n",
    "    \n",
    "    return geobuildings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee20371c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-09T13:07:07.641006Z",
     "start_time": "2024-02-09T13:07:07.630131Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_enriched_data_dask(country,dataset):\n",
    "    import dask_geopandas as dgpd\n",
    "    import pandas as pd\n",
    "    import datetime\n",
    "    print(datetime.datetime.now(),'importing',country,dataset)\n",
    "    geobuildings=dgpd.read_file('/mnt/CAS/20240101_foss4g/datasets/in/countries/%s/%s_enriched.gpkg'%(country,dataset),npartitions=10)\n",
    "    geobuildings.crs='epsg:4326'\n",
    "    geobuildings=geobuildings.compute()\n",
    "    if dataset=='microsoft':\n",
    "        if not('microsoft-id' in list(geobuildings.columns)):\n",
    "            geobuildings['microsoft-id']=geobuildings.index\n",
    "    \n",
    "    for col in ['area_sqm','num_vertices']:\n",
    "        column_dtype = geobuildings[col].dtype\n",
    "        if column_dtype == 'object':\n",
    "            print(datetime.datetime.now(),\"The column %s contains strings. We convert to float\" %(col))\n",
    "            geobuildings[col] = pd.to_numeric(geobuildings[col], errors='coerce')\n",
    "    \n",
    "    return geobuildings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acbc1b7",
   "metadata": {},
   "source": [
    "# Spatial Join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e7229fd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-06T14:37:52.471065Z",
     "start_time": "2024-02-06T14:37:52.460576Z"
    }
   },
   "outputs": [],
   "source": [
    "def building_to_nuts(geo_buildings):\n",
    "    \n",
    "    def count_vertices(geometry):\n",
    "        from shapely.geometry import Polygon, MultiPolygon\n",
    "        if isinstance(geometry, Polygon):\n",
    "            return len(geometry.exterior.coords) - 1\n",
    "        elif isinstance(geometry, MultiPolygon):\n",
    "            total_vertices = 0\n",
    "            for polygon in geometry:\n",
    "                total_vertices += len(polygon.exterior.coords) - 1\n",
    "            return total_vertices\n",
    "        else:\n",
    "            return None  # Handle other geometry types if needed\n",
    "\n",
    "\n",
    "    import geopandas as gpd\n",
    "    import pandas as pd\n",
    "    import warnings\n",
    "    import datetime\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    zipped_shapefile_path = '/mnt/CAS/20240101_foss4g/datasets/in/NUTS_RG_01M_2016_4326.shp.zip'\n",
    "    gdf_lau = gpd.read_file('zip://' + zipped_shapefile_path)\n",
    "    country=geo_buildings.head(1)['country'].values[0]\n",
    "    geo_lau=gdf_lau[(gdf_lau['CNTR_CODE']==country) &(gdf_lau['LEVL_CODE']==3)]\n",
    "    #print(datetime.datetime.now(),' ',len(geo_lau),'nr of lau3 regions per country')\n",
    "    #print(datetime.datetime.now(),'computing area in sqm with Mercatore projection for',len(geo_buildings),'rows')\n",
    "    geo_buildings['area']=geo_buildings['geometry'].to_crs({'init': 'epsg:3857'}).map(lambda p: int(p.area ))\n",
    "    # Apply the function to the 'geometry' column and create a new column 'num_vertices'\n",
    "    geo_buildings['num_vertices'] = geo_buildings['geometry'].apply(lambda x:count_vertices(x))\n",
    "\n",
    "    if geo_buildings.crs!='epsg:4326':\n",
    "        #print(datetime.datetime.now(),'converting to WGS84')\n",
    "        geo_buildings=geo_buildings.to_crs(4326)\n",
    "    \n",
    "    #print(datetime.datetime.now(),'merging buildings and',len(geo_lau),'Lau3 layer')\n",
    "    result = gpd.sjoin(geo_buildings, geo_lau[['NUTS_ID','URBN_TYPE','NUTS_NAME','geometry']], how='inner', op='intersects')\n",
    "    result.columns=list(geo_buildings.columns)+['idx_right','nuts_id','urban_type','nuts_name']\n",
    "    del(result['idx_right'])\n",
    "    #print(datetime.datetime.now(),'returning results')\n",
    "    return result\n",
    "\n",
    "def process_buildings_to_lau_parallel(geo_buildings):\n",
    "    import warnings\n",
    "    import datetime\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    import geopandas as gpd\n",
    "    import multiprocessing as mp\n",
    "    from pathos.multiprocessing import ProcessingPool as Pool\n",
    "    cores=mp.cpu_count()\n",
    "    df_split = np.array_split(geo_buildings, cores, axis=0)\n",
    "    pool = Pool(cores)\n",
    "    df_out = np.vstack(pool.map(building_to_nuts, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    pool.clear()\n",
    "\n",
    "    #merging and aggregating results\n",
    "    result_parallel=pd.DataFrame(df_out)\n",
    "    result_parallel.columns=list(geo_buildings.columns)+['area_sqm','num_vertices','nuts_id','urban_type','nuts_name']\n",
    "    result_parallel=gpd.GeoDataFrame(result_parallel,geometry='geometry')\n",
    "    return result_parallel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b690d5a",
   "metadata": {},
   "source": [
    "# Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f1abd81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T17:29:03.635834Z",
     "start_time": "2024-02-07T17:29:03.631620Z"
    }
   },
   "outputs": [],
   "source": [
    "def aggregation(geobuildings):\n",
    "    import pandas as pd\n",
    "    functions = {\n",
    "    'geometry': 'count',\n",
    "    'area_sqm': 'sum',\n",
    "    'num_vertices':'sum'\n",
    "    }\n",
    "\n",
    "    # Apply different functions to group by 'Group' column\n",
    "    buildings_stat = pd.DataFrame(geobuildings.groupby(['dataset','source','nuts_id','nuts_name','urban_type','country']).agg(functions)).reset_index()\n",
    "    buildings_stat = buildings_stat.rename(columns={'geometry': 'nr_buildings'})\n",
    "\n",
    "    print(datetime.datetime.now(),'total number of regions computed:',len(buildings_stat))\n",
    "    return buildings_stat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47545b8a",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6b25f8db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-02-07T12:56:51.241075Z",
     "start_time": "2024-02-07T12:56:51.138419Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_country_geometries(country):\n",
    "    import geopandas as gpd\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    sns.set_style(\"white\")\n",
    "    from matplotlib.colors import ListedColormap\n",
    "    from matplotlib.patches import Patch\n",
    "\n",
    "    # Create a custom legend handler for the intersection\n",
    "    class YellowBoxHandler(Patch):\n",
    "        def __init__(self, color='yellow', alpha=0.5, **kwargs):\n",
    "            super().__init__(color=color, alpha=alpha, **kwargs)\n",
    "\n",
    "    # Importing country\n",
    "    geo_lau = load_nuts(country)\n",
    "    geo_lau['URBN_TYPE'] = [str(val) for val in geo_lau['URBN_TYPE'].values]\n",
    "\n",
    "    #computing total area per urban type\n",
    "    geo_lau['area']=geo_lau['geometry'].to_crs({'init': 'epsg:3857'}).map(lambda p: int(p.area ))\n",
    "\n",
    "    # Define custom colors for each urban type\n",
    "    custom_colors = {\n",
    "        '1': 'darkred',  # Dark red for urban type 1\n",
    "        '2': 'blue',     # Blue for urban type 2\n",
    "        '3': 'green'     # Green for urban type 3\n",
    "    }\n",
    "    geo_lau['colors']=[custom_colors[val] for val in geo_lau['URBN_TYPE'].values]\n",
    "    # Set Seaborn style\n",
    "\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(12, 10))\n",
    "\n",
    "    #statistic about area\n",
    "    import numpy as np\n",
    "    area_stat=pd.DataFrame(geo_lau.groupby(['URBN_TYPE'])['area'].sum()).to_dict(orient='index')\n",
    "    sum_area=0.0\n",
    "    for ut in area_stat:\n",
    "        if ut!='3':\n",
    "            a=np.round(area_stat[ut]['area']/geo_lau['area'].sum()*100,2)\n",
    "            area_stat[ut]=a\n",
    "            sum_area+=a\n",
    "        else:\n",
    "            area_stat[ut]=np.round(100-sum_area,2)\n",
    "    for key in ['1','2','3']:\n",
    "        if not(key in area_stat):\n",
    "            area_stat[key]=0\n",
    "\n",
    "    # Plot GeoDataFrame with the created ListedColormap\n",
    "    geo_lau.plot(column='URBN_TYPE', legend=True, color=geo_lau['colors'], edgecolor=\"none\",alpha=0.8)\n",
    "\n",
    "    # Add title and labels if needed\n",
    "    plt.title('%s by Degree of Urbanization' % (country))\n",
    "    plt.xlabel('Longitude')\n",
    "    plt.ylabel('Latitude')\n",
    "    #Cities; Towns and suburbs; Rural areas\n",
    "    legend_labels = ['Urban ('+str(area_stat['1'])+' %)', 'Semi Urban ('+str(area_stat['2'])+' %)', 'Rural ('+str(area_stat['3'])+' %)']\n",
    "\n",
    "    # Create legend handles\n",
    "    handles = [\n",
    "        YellowBoxHandler(color='darkred', alpha=0.8),\n",
    "        YellowBoxHandler(color='blue', alpha=0.8),\n",
    "        YellowBoxHandler(color='green', alpha=0.8)\n",
    "    ]\n",
    "\n",
    "    # Create the legend\n",
    "    plt.legend(handles=handles, labels=legend_labels,bbox_to_anchor=(0.5, -0.18), ncol=2,loc='upper center')\n",
    "\n",
    "    plt.subplots_adjust(bottom=0.26)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.savefig('/mnt/CAS/20240101_foss4g/plots/countries/%s.png' %(country),dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cuda_env)",
   "language": "python",
   "name": "cuda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
